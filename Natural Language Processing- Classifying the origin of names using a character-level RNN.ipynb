{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeERWemNFXXt"
      },
      "source": [
        "# Natural Language Processing- Classifying the origin of names using a character-level RNN\n",
        "\n",
        "In this task, I used rnn-based model to perform classification. The aim include:\n",
        "\n",
        "1. To get started with the preprocessing needed to perform text classification from A to Z.\n",
        "2. Use embeddings and RNNs in conjunction at the character level to perform classification.\n",
        "3. Write a function that takes as input a string, and outputs the name of the predicted class.\n",
        "\n",
        "To do this, I followed these steps:\n",
        "\n",
        "1. Decide the number of classes, and map the classes to integers (or one-hot vectors). This is needed for fitting the model and training it to do classification.\n",
        "2. Use the keras tokenizer at the character level to tokenize input into integer sequences.\n",
        "3. Pad sequences using the keras preprocessing tools.\n",
        "4. Build a model that uses, minimally, an embedding layer, an RNN and a dense layer to output the logits or probabilities for the target classes (name origins).\n",
        "5. Fit the model and evaluate on the test set.\n",
        "6. Write a function that takes a string as input and predicts the origin (as its original string value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pk04RfJK97Ju"
      },
      "outputs": [],
      "source": [
        "#!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS9ty_yBFJSg",
        "outputId": "e624b8ff-4fa1-42ca-ee6f-70edb62c4137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-2dbee37c3c0d>:12: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner import HyperModel\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Bidirectional, Dropout\n",
        "from kerastuner import HyperModel\n",
        "import kerastuner as kt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Xq18_khFcsK",
        "outputId": "3b896efa-d3c6-4ed4-c36f-5dc8d4e7e1d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-06-29 03:10:00--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.35.35.91, 13.35.35.99, 13.35.35.55, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.35.35.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   2.75M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-06-29 03:10:01 (76.6 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n",
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ]
        }
      ],
      "source": [
        "# Download the data\n",
        "!wget https://download.pytorch.org/tutorial/data.zip\n",
        "!unzip data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dIWLuUg0FddK"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "for filename in glob('data/names/*.txt'):\n",
        "  origin = filename.split('/')[-1].split('.txt')[0]\n",
        "  names = open(filename).readlines()\n",
        "  for name in names:\n",
        "    data.append((name.strip(), origin))\n",
        "\n",
        "names, origins = zip(*data)\n",
        "names_train, names_test, origins_train, origins_test = train_test_split(names, origins, test_size=0.25, shuffle=True, random_state=123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO3XMMfGFhIR"
      },
      "source": [
        "# Look at the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaPRdXKlFfCY",
        "outputId": "befa580d-22c1-4e97-e44b-51205949aef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Davidson             Scottish\n",
            "Vyalko               Russian\n",
            "Jahaev               Russian\n",
            "Woo                  Korean\n",
            "Abana                Spanish\n",
            "Atiyeh               Arabic\n",
            "Minyukov             Russian\n",
            "Bachmeier            German\n",
            "Gershkovitsh         Russian\n",
            "Albinesku            Russian\n",
            "Badyin               Russian\n",
            "Androsyuk            Russian\n",
            "Judasin              Russian\n",
            "Velichkin            Russian\n",
            "Viron                Russian\n",
            "Kattan               Arabic\n",
            "Ashbridge            English\n",
            "Major                English\n",
            "Hilton               English\n",
            "Hunov                Russian\n"
          ]
        }
      ],
      "source": [
        "for name, origin in zip(names_train[:20], origins_train[:20]):\n",
        "  print(name.ljust(20), origin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF1KOZSLsTdE"
      },
      "source": [
        "#### Map the classes to integers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lTBCY2XzsSbv"
      },
      "outputs": [],
      "source": [
        "origins_set = set(origins_train)\n",
        "origin_to_int = {origin: i for i, origin in enumerate(origins_set)}\n",
        "int_to_origin = {i: origin for origin, i in origin_to_int.items()}\n",
        "\n",
        "origins_train_int = [origin_to_int[origin] for origin in origins_train]\n",
        "origins_test_int = [origin_to_int[origin] for origin in origins_test]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzAlsZToso_8"
      },
      "source": [
        "#### Tokenize the names at the character level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "x9GXSGhRslgu"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(names_train)\n",
        "\n",
        "names_train_seq = tokenizer.texts_to_sequences(names_train)\n",
        "names_test_seq = tokenizer.texts_to_sequences(names_test)\n",
        "\n",
        "max_length = max(len(seq) for seq in names_train_seq)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lIuJ3mbs7_U"
      },
      "source": [
        "#### Pad the sequences to ensure they are all of the same length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ohnpD6eZs5Vn"
      },
      "outputs": [],
      "source": [
        "names_train_padded = pad_sequences(names_train_seq, maxlen=max_length, padding='post')\n",
        "names_test_padded = pad_sequences(names_test_seq, maxlen=max_length, padding='post')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o7l3sfAtRWR"
      },
      "source": [
        "#### Build a model using an embedding layer, and a dense layer to output the logits for the target classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "b8hpWnR7tOVg"
      },
      "outputs": [],
      "source": [
        "# Define vocab_size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Convert names_train_padded and origins_train_int to NumPy arrays\n",
        "names_train_padded = np.array(names_train_padded)\n",
        "origins_train_int = np.array(origins_train_int)\n",
        "\n",
        "\n",
        "# Define the HyperModel\n",
        "class MyHyperModel(HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = Sequential()\n",
        "        model.add(Embedding(\n",
        "            input_dim=vocab_size,\n",
        "            output_dim=hp.Int('embedding_dim', min_value=32, max_value=128, step=32),\n",
        "            input_length=max_length\n",
        "        ))\n",
        "        model.add(Bidirectional(LSTM(\n",
        "            units=hp.Int('lstm_units', min_value=64, max_value=256, step=64),\n",
        "            return_sequences=True\n",
        "        )))\n",
        "        model.add(Bidirectional(GRU(\n",
        "            units=hp.Int('gru_units', min_value=64, max_value=256, step=64)\n",
        "        )))\n",
        "        model.add(Dropout(rate=hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "        model.add(Dense(len(origins_set), activation='softmax'))\n",
        "\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        return model\n",
        "\n",
        "hypermodel = MyHyperModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2foKnEM_RxZ",
        "outputId": "cf217c6f-6446-4c15-869d-4a27a3df5a44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reloading Tuner from my_dir/name_origin_classification/tuner0.json\n"
          ]
        }
      ],
      "source": [
        "# Set up the tuner\n",
        "tuner = kt.Hyperband(\n",
        "    hypermodel,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=20,\n",
        "    factor=3,\n",
        "    directory='my_dir',\n",
        "    project_name='name_origin_classification'\n",
        ")\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aPUa3sc_p9T",
        "outputId": "51e48824-4da9-46f0-8f92-db709b6d2ae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 26 Complete [00h 00m 57s]\n",
            "val_accuracy: 0.81401526927948\n",
            "\n",
            "Best val_accuracy So Far: 0.8189970254898071\n",
            "Total elapsed time: 00h 15m 42s\n"
          ]
        }
      ],
      "source": [
        "# Perform hyperparameter tuning\n",
        "tuner.search(names_train_padded, origins_train_int, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvgL6Dv4tk8i"
      },
      "source": [
        "#### Fit the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWItoXM5th4B"
      },
      "outputs": [],
      "source": [
        "# train the model with the best hyperparameters\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "model.fit(names_train_padded, origins_train_int, epochs=50, validation_split=0.2, callbacks=[stop_early])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx3Y4XSBtoUS"
      },
      "source": [
        "#### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rewXNVxftoAi",
        "outputId": "2e008289-40bd-4783-80cb-95aae9f4466d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 1s 4ms/step - loss: 0.6821 - accuracy: 0.8283\n",
            "Test Accuracy: 0.8283\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "names_test_padded = np.array(names_test_padded)\n",
        "origins_test_int = np.array(origins_test_int)\n",
        "\n",
        "loss, accuracy = model.evaluate(names_test_padded, origins_test_int)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M27oKV-ZtzIj"
      },
      "source": [
        "#### Write a function to predict the origin of names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "b5Y5lkChtzeI"
      },
      "outputs": [],
      "source": [
        "def predict_origin(*names):\n",
        "    predictions = {}\n",
        "    for name in names:\n",
        "        assert isinstance(name, str)\n",
        "        name_seq = tokenizer.texts_to_sequences([name])\n",
        "        name_padded = pad_sequences(name_seq, maxlen=max_length, padding='post')\n",
        "        prediction = model.predict(name_padded)\n",
        "        predicted_class = np.argmax(prediction, axis=1)[0]\n",
        "        predictions[name] = int_to_origin[predicted_class]\n",
        "    return predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztQkT1CbuFEJ",
        "outputId": "ff161b2d-78ea-48f6-9847-553abe5ccf44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "The predicted origin of Justin is English.\n",
            "The predicted origin of Trudeau is French.\n"
          ]
        }
      ],
      "source": [
        "#Apply the function\n",
        "\n",
        "predicted_origins = predict_origin(\"Justin\", \"Trudeau\")\n",
        "for name, origin in predicted_origins.items():\n",
        "    print(f\"The predicted origin of {name} is {origin}.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
